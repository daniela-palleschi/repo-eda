[
  {
    "objectID": "assumptions.html",
    "href": "assumptions.html",
    "title": "8  Model assumptions",
    "section": "",
    "text": "Learning objectives\nToday we will learn…\nSections 6.3, 6.4 and 7.9 in (winter_statistics_2019?)\n# suppress scientific notation\noptions(scipen=999)\n\\[\n\\begin{align}\nobserved\\;values &= fitted\\;values + residuals\\\\\nresiduals &= observed\\;values - fitted\\;values\n\\end{align}\n\\]\ndf_crit_verb |&gt; \n  filter(fp &gt; 0) |&gt; \n  mutate(half = if_else(trial &gt;= 104, \"1st\",\"2nd\")) |&gt; \n  ggpubr::ggqqplot(x = \"fp\")\npacman::p_load(car)\nvif(fit_fp)\n\n      lifetime          tense lifetime:tense \n      1.000169       1.000169       1.000007\nperformance::check_model(fit_fp_log)\n\n\n\n\nFigure 15.1: Performance of model with log reading times\nperformance::check_model(fit_fp)\n\n\n\n\nFigure 15.2: Performance of model with log reading times\ntidy(fit_fp_log) %&gt;% \n  kable(digits = 10,\n        col.names = c(\"Coefficient\",\n                      \"Estimate (log)\",\n                      \"SE\",\n                      \"t-value\",\n                      \"p-value\")) %&gt;% \n  kable_styling()\n\n\n\n\nCoefficient\nEstimate (log)\nSE\nt-value\np-value\n\n\n\n\n(Intercept)\n5.63476711\n0.01877047\n300.1931843\n0.000000000\n\n\nlifetime1\n0.10130415\n0.03754094\n2.6984981\n0.007183743\n\n\ntense1\n-0.03357132\n0.03754094\n-0.8942589\n0.371582493\n\n\nlifetime1:tense1\n-0.08320391\n0.07508188\n-1.1081757\n0.268280198"
  },
  {
    "objectID": "assumptions.html#packages",
    "href": "assumptions.html#packages",
    "title": "8  Model assumptions",
    "section": "Packages",
    "text": "Packages\n\npacman::p_load(tidyverse,\n               broom,\n               patchwork,\n               sjPlot,\n               knitr,\n               kableExtra,\n               Rmisc)"
  },
  {
    "objectID": "assumptions.html#data",
    "href": "assumptions.html#data",
    "title": "8  Model assumptions",
    "section": "Data",
    "text": "Data\n\nforce character variables to factors\nfilter for the verb region from critical items only, remove participant 3, and remove values of first-fixtation that are\n\n\n# load in dataset\ndf_crit_verb &lt;-\n  readr::read_csv(\n    here::here(\"data/tidy_data_lifetime_pilot.csv\"),\n    # for special characters\n    locale = readr::locale(encoding = \"latin1\")\n  ) |&gt;\n  mutate_if(is.character, as.factor) |&gt; # all character variables as factor\n  mutate(lifetime = fct_relevel(lifetime, \"living\", \"dead\"),\n         tense = fct_relevel(tense, \"PP\", \"SF\")) |&gt;\n  filter(type == \"critical\", # only critical trials\n         px != \"px3\", # px3 had a lot of missing values\n         fp &gt; 0, # only values of fp above 0\n         region == \"verb\") %&gt;% # critical region only\n  droplevels() # remove any factor levels with no observations"
  },
  {
    "objectID": "assumptions.html#our-model",
    "href": "assumptions.html#our-model",
    "title": "8  Model assumptions",
    "section": "9.1 Our model",
    "text": "9.1 Our model\n\n9.1.1 Check contrasts\n\ncontrasts(df_crit_verb$lifetime)\n\n       dead\nliving    0\ndead      1\n\n\n\ncontrasts(df_crit_verb$tense)\n\n   SF\nPP  0\nSF  1\n\n\n\n\n9.1.2 Re-order predictor levels\n\n# set contrasts\ndf_crit_verb &lt;- df_crit_verb %&gt;% \n  mutate(lifetime = fct_relevel(lifetime, \"living\", \"dead\"),\n         tense = fct_relevel(tense, \"PP\", \"SF\"))\n\n\n\n9.1.3 Set sum coding\nSet contrasts\n\ncontrasts(df_crit_verb$lifetime) &lt;- c(-0.5, +0.5)\ncontrasts(df_crit_verb$tense) &lt;- c(-0.5, +0.5)\n\nCheck contrasts\n\ncontrasts(df_crit_verb$lifetime)\n\n       [,1]\nliving -0.5\ndead    0.5\n\n\n\ncontrasts(df_crit_verb$tense)\n\n   [,1]\nPP -0.5\nSF  0.5\n\n\n\n\n9.1.4 Run model\n\n# fit linear model\nfit_fp &lt;- df_crit_verb %&gt;%\n  lm(fp ~ lifetime*tense, data = .)\n\n\n\n9.1.5 Print summary\n\nsummary(fit_fp)\n\n\nCall:\nlm(formula = fp ~ lifetime * tense, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-240.62 -108.69  -27.62   56.20  778.65 \n\nCoefficients:\n                 Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)        309.06       6.26  49.367 &lt;0.0000000000000002 ***\nlifetime1           31.52      12.52   2.517              0.0121 *  \ntense1             -12.75      12.52  -1.018              0.3090    \nlifetime1:tense1   -21.69      25.04  -0.866              0.3868    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 145.9 on 539 degrees of freedom\nMultiple R-squared:  0.01499,   Adjusted R-squared:  0.009506 \nF-statistic: 2.734 on 3 and 539 DF,  p-value: 0.04306"
  },
  {
    "objectID": "assumptions.html#checking-assumptions",
    "href": "assumptions.html#checking-assumptions",
    "title": "8  Model assumptions",
    "section": "10.1 Checking assumptions",
    "text": "10.1 Checking assumptions\n\nwe typically assess normality and homoscedasticity visually with histograms, Q-Q plots, and residual plots\nwe can assess collinearity with VIFs\nthe assumption of independence is dealt with conceptually\n\n\n\n\n\n\nImage source: (winter_statistics_2019?) (all rights reserved)"
  },
  {
    "objectID": "assumptions.html#normality-assumption-1",
    "href": "assumptions.html#normality-assumption-1",
    "title": "8  Model assumptions",
    "section": "Normality assumption",
    "text": "Normality assumption\n\nhow about by participant and experimental half?\n\n\ndf_crit_verb |&gt; \n  filter(fp &gt; 0) |&gt; \n  mutate(half = if_else(trial &gt;= 104, \"1st\",\"2nd\")) |&gt; \n  ggpubr::ggqqplot(x = \"fp\",\n                    color = \"half\",\n                    facet.by = \"px\")"
  },
  {
    "objectID": "assumptions.html#normality-assumption-2",
    "href": "assumptions.html#normality-assumption-2",
    "title": "8  Model assumptions",
    "section": "Normality assumption",
    "text": "Normality assumption\n\nnormal distribution is symmetrical, are our residuals normally distributed?\n\n\n\n\n\n\nFigure 12.1: Visualising normality of residuals"
  },
  {
    "objectID": "assumptions.html#normality-assumption-3",
    "href": "assumptions.html#normality-assumption-3",
    "title": "8  Model assumptions",
    "section": "Normality assumption",
    "text": "Normality assumption\n\nreading time data tends to be positively skewed\n\nso the residuals also tend to be positively skewed\n\ndata with a skewed distribution do not meet the normality assumption\na fix: nonlinear transformations\n\nthe most common: the log transformation\n\nlog-transforming your data makes larger numbers smaller (and small numbers smaller too)\n\nthe difference between smaller numbers and larger numbers shrinks\ncan make skewed data normally distributed\n\n\n\n12.0.1 Log transformation\n\nfor more see Section 5.4 in (winter_statistics_2019?)\nthe R funtion log() computes the ‘natural logarithm’ (and is the inverse of the exponential exp())\nlog() makes large numbers smaller\nexp() makes small numbers larger\n\n\nlog(2)\n\n[1] 0.6931472\n\n\n\nlog(1:10)\n\n [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 1.7917595 1.9459101\n [8] 2.0794415 2.1972246 2.3025851\n\n\n\nlog(c(10,20,30,40,100))\n\n[1] 2.302585 2.995732 3.401197 3.688879 4.605170\n\n\n\nexp(1:10)\n\n [1]     2.718282     7.389056    20.085537    54.598150   148.413159\n [6]   403.428793  1096.633158  2980.957987  8103.083928 22026.465795\n\n\n\nexp(log(1:10))\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "assumptions.html#fit-model-log-transformed",
    "href": "assumptions.html#fit-model-log-transformed",
    "title": "8  Model assumptions",
    "section": "12.1 Fit model (log-transformed)",
    "text": "12.1 Fit model (log-transformed)\n\ncontinuous variables truncated at 0 typically have a positive skew\n\na lot of small values (e.g., tt &lt; 500ms), with some larger values (&gt; tt 1000)\nthis usually means our residuals are also positively skewed, i.e., not normally distributed\n\nso we typically log-transform raw reading/reaction times for our linear models\n\n\n# fit simple linear model with log\nfit_fp_log &lt;- df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;% # important! you can't log transform 0\n  lm(log(fp) ~ lifetime*tense, data = .)\nsummary(fit_fp_log)\n\n\nCall:\nlm(formula = log(fp) ~ lifetime * tense, data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.18141 -0.34282  0.00058  0.26923  1.38822 \n\nCoefficients:\n                 Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)       5.63477    0.01877 300.193 &lt; 0.0000000000000002 ***\nlifetime1         0.10130    0.03754   2.698              0.00718 ** \ntense1           -0.03357    0.03754  -0.894              0.37158    \nlifetime1:tense1 -0.08320    0.07508  -1.108              0.26828    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4374 on 539 degrees of freedom\nMultiple R-squared:  0.01712,   Adjusted R-squared:  0.01165 \nF-statistic: 3.129 on 3 and 539 DF,  p-value: 0.02538\n\n\n\n12.1.1 Check assumptions\n\n\nRaw first-pass reading times\n\nplot(density(resid(fit_fp)))\n\n\n\n\n\nLog first-pass reading times\n\nplot(density(resid(fit_fp_log)))\n\n\n\n\n\n\n\n\nCheck assumptions\n\n\nRaw first-pass reading times\n\nqqnorm(residuals(fit_fp))\nqqline(residuals(fit_fp), col=\"red\")\n\n\n\n\n\nLog first-pass reading times\n\nqqnorm(residuals(fit_fp_log))\nqqline(residuals(fit_fp_log), col=\"red\")\n\n\n\n\n\n\n\n\nCheck assumptions: constant variance\n\n\nRaw first-pass reading times\n\nfit_fp %&gt;% \nggplot(aes(x = .fitted, y = .resid)) +\n  labs(title = \"Residual plot (fp ~ lifetime*tense)\") +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw()  # Add theme for cleaner look\n\n\n\n\n\nLog first-pass reading times\n\nfit_fp_log %&gt;% \nggplot(aes(x = .fitted, y = .resid)) +\n  labs(title = \"Residual plot (log(fp) ~ lifetime*tense)\") +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw()  # Add theme for cleaner look\n\n\n\n\n\n\n\n\n12.1.2 Approaching normality: log\n\nso it seems like the log-transformed values have made the data more normal"
  },
  {
    "objectID": "assumptions.html#interpreting-log",
    "href": "assumptions.html#interpreting-log",
    "title": "8  Model assumptions",
    "section": "12.2 Interpreting log",
    "text": "12.2 Interpreting log\n\naugment(fit_fp_log, data = df_crit_verb[df_crit_verb$fp &gt; 0,]) %&gt;% \n  distinct(lifetime,tense,.fitted) %&gt;% \n  arrange(lifetime) \n\n# A tibble: 4 × 3\n  lifetime tense .fitted\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;\n1 living   PP       5.58\n2 living   SF       5.59\n3 dead     PP       5.72\n4 dead     SF       5.65\n\n\n\ndf_crit_verb %&gt;% \n  mutate(predicted_raw = predict(fit_fp),\n         predicted_log = predict(fit_fp_log)) %&gt;% \n  distinct(lifetime,tense,predicted_raw, predicted_log) %&gt;% \n  arrange(lifetime) \n\n# A tibble: 4 × 4\n  lifetime tense predicted_raw predicted_log\n  &lt;fct&gt;    &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 living   PP             294.          5.58\n2 living   SF             292.          5.59\n3 dead     PP             337.          5.72\n4 dead     SF             313.          5.65\n\n\n\n\nexp(coef(fit_fp_log)['(Intercept)'])\n\n(Intercept) \n   279.9937 \n\ncoef(fit_fp)['(Intercept)']\n\n(Intercept) \n   309.0606 \n\n\n\nthe exponential (back-transformation) of the log slopes correspond to the change in percentage\n\n\n(exp(coef(fit_fp_log)['lifetime1'])-1)*100\n\nlifetime1 \n 10.66132 \n\n\n\n(exp(coef(fit_fp_log)['tense1'])-1)*100\n\n   tense1 \n-3.301406 \n\n\n\n# living-SF\ncoef(fit_fp)['(Intercept)'] + (coef(fit_fp)['lifetime1'] * -0.5)\n\n(Intercept) \n    293.302 \n\nexp(coef(fit_fp_log)['(Intercept)']) * (exp(coef(fit_fp_log)['lifetime1']* -0.5))\n\n(Intercept) \n   266.1646 \n\nexp(coef(fit_fp_log)['(Intercept)']) * (exp(coef(fit_fp_log)['lifetime1']* +0.5))\n\n(Intercept) \n   294.5413 \n\n\n\n# living-SF\nexp(coef(fit_fp_log)['(Intercept)']) * exp(coef(fit_fp_log)['lifetime1'] * -0.5 + coef(fit_fp_log)['tense1'] * -0.5 )\n\n(Intercept) \n   270.6701 \n\n\n\n# dead-PP\nexp(coef(fit_fp_log)['(Intercept)']) * exp(coef(fit_fp_log)['lifetime1'] * +0.5 + coef(fit_fp_log)['tense1'] * -0.5 )\n\n(Intercept) \n   299.5271 \n\n\n\n# dead-SF\ncoef(fit_fp_log)['(Intercept)'] + coef(fit_fp_log)['lifetime1'] * 0.5 + coef(fit_fp_log)['tense1'] * 0.5 \n\n(Intercept) \n   5.668634"
  },
  {
    "objectID": "assumptions.html#what-is-independence-of-data",
    "href": "assumptions.html#what-is-independence-of-data",
    "title": "8  Model assumptions",
    "section": "14.1 What is (in)dependence of data?",
    "text": "14.1 What is (in)dependence of data?\n\ne.g., each roll of a die is independent\n\nthat is, if you roll a 6, this has no bearing on what you will roll next\nif you roll a die 10 times and I roll a die 10 times, the values we get will not be linked to who rolled the die\n\nreading times are dependent\n\nif we collect eye-tracking reading times from two people, the data points from each person will be dependent\n\nthis is because each person will have their own reading pace, so their data points will tend to cluster\n\nalso true for experimental item\n\nsome items will likely elicit a stronger effect than others"
  },
  {
    "objectID": "assumptions.html#check-independence",
    "href": "assumptions.html#check-independence",
    "title": "8  Model assumptions",
    "section": "14.2 Check independence",
    "text": "14.2 Check independence\n\nindependence is a conceptual consideration, it can’t be checked visually or numerically\nit is a question of experimental design\na way to think about it: can my data be linked/clustered/grouped by some means?\n\ne.g., yes, by participant, by item, even by verb\n\nthere of course are many ways our data might cluster, contributing random error that would not be expected to be repeated\n\nwe have specific predictions for the effects of lifetime or tense, and would expect them to replicate if we were to re-run the study\nbut we cannot predict how certain participants will pattern, nor how certain items will pattern\nthese are random variables, essentially error that we can try to explain by means of telling the model “check for effects by participant and item”"
  },
  {
    "objectID": "assumptions.html#accounting-for-independence",
    "href": "assumptions.html#accounting-for-independence",
    "title": "8  Model assumptions",
    "section": "14.3 Accounting for independence",
    "text": "14.3 Accounting for independence\n\nthere is a very powerful tool that allows us to include dependence in our models: linear mixed models (LMMs)\nLMMs are mixed because they include fixed effects (lifetime, tense), and random effects (in eye-tracking experiments, typically participant, item)\n\nalso called linear mixed effects models (LMEMs), or multilevel models (or hierarchical models in some cases)"
  },
  {
    "objectID": "assumptions.html#p-value-formatting",
    "href": "assumptions.html#p-value-formatting",
    "title": "8  Model assumptions",
    "section": "16.1 P-value formatting",
    "text": "16.1 P-value formatting\n\nyou can create a function the replaces p-values\n\n\n# source: https://stackoverflow.com/questions/37470202/in-line-code-for-reporting-p-values-001-in-r-markdown\n# OR USE\npacman::p_load(broman) \nformat_pval &lt;- function(x){\n  if (x &lt; .001) return(paste('&lt;', '.001'))\n  if (x &lt; .01) return(paste('&lt;', '.01'))\n  if (x &lt; .05) return(paste('&lt;', '.05'))\n  paste('=', myround(x, 3))  # if above .05, print p-value to 3 decimalp points\n}\n\n\nmake_stars &lt;- function(pval) {\n  stars = \"\"\n  if(pval &lt;= 0.001)\n    stars = \"***\"\n  if(pval &gt; 0.001 & pval &lt;= 0.01)\n    stars = \"**\"\n  if(pval &gt; 0.01 & pval &lt;= 0.05)\n    stars = \"*\"\n  if(pval &gt; 0.05 & pval &lt;= 0.1)\n     stars = \".\"\n  stars\n}"
  },
  {
    "objectID": "assumptions.html#formatted-table",
    "href": "assumptions.html#formatted-table",
    "title": "8  Model assumptions",
    "section": "16.2 Formatted table",
    "text": "16.2 Formatted table\n\ntidy(fit_fp_log) %&gt;% \n  mutate(format = sapply(p.value, function(x) format_pval(x))) %&gt;% \n  mutate(signif = sapply(p.value, function(x) make_stars(x))) %&gt;%\n  select(-p.value) %&gt;% \n  kable(digits = 10,\n        col.names = c(\"Coefficient\",\n                      \"Estimate (log)\",\n                      \"SE\",\n                      \"t-value\",\n                      \"p-value\",\n                      \"sign\")) %&gt;% \n  kable_styling()\n\n\n\n\nCoefficient\nEstimate (log)\nSE\nt-value\np-value\nsign\n\n\n\n\n(Intercept)\n5.63476711\n0.01877047\n300.1931843\n&lt; .001\n***\n\n\nlifetime1\n0.10130415\n0.03754094\n2.6984981\n&lt; .01\n**\n\n\ntense1\n-0.03357132\n0.03754094\n-0.8942589\n= 0.372\n\n\n\nlifetime1:tense1\n-0.08320391\n0.07508188\n-1.1081757\n= 0.268"
  },
  {
    "objectID": "assumptions.html#plots",
    "href": "assumptions.html#plots",
    "title": "8  Model assumptions",
    "section": "16.3 Plots",
    "text": "16.3 Plots\n\ndf_crit_verb |&gt; \n  filter(fp &gt; 0) |&gt; \n  mutate(log_ff = log(fp)) |&gt; \n  mutate(half = if_else(trial &gt;= 104, \"1st\",\"2nd\")) |&gt; \n  ggpubr::ggqqplot(x = \"log_ff\")\n\n\n\n\n\n16.3.1 sjPlot\n\n\n\n\n\nFigure 16.1: ?(caption)\n\n\n\n\n\n\n16.3.2 Distributions\n\n\n\n\n\nFigure 16.2: ?(caption)\n\n\n\n\n\n\n16.3.3 Errorbar\n\nfig_error &lt;-\n  df_crit_verb %&gt;% \n  filter(fp &gt; 0) %&gt;% \n  summarySEwithin(measurevar=\"fp\", withinvars=c(\"lifetime\", \"tense\"), idvar=\"px\") %&gt;% \n  mutate(upper = fp+ci,\n         lower = fp-ci) %&gt;% \n  ggplot(aes(x = lifetime, y = fp, colour = tense, shape = tense)) + \n  labs(title = \"Mean first-pass reading times (with 95% CIs)\") +\n  geom_point(position = position_dodge(0.2), size = 2) +\n  geom_line(position = position_dodge(0.2), aes(group=tense)) +\n  geom_errorbar(aes(ymin=lower,ymax=upper), position = position_dodge(0.2), width = .2) +\n  theme_bw() +\n  theme(text = element_text(size=8))\n\nfig_error_log &lt;-\n  df_crit_verb %&gt;% \n  filter(fp &gt; 0) %&gt;% \n  mutate(fp_log = log(fp)) %&gt;% \n  summarySEwithin(measurevar=\"fp_log\", withinvars=c(\"lifetime\", \"tense\"), idvar=\"px\") %&gt;% \n  mutate(upper = fp_log+ci,\n         lower = fp_log-ci) %&gt;% \n  ggplot(aes(x = lifetime, y = fp_log, colour = tense, shape = tense)) + \n  labs(title = \"Mean first-pass reading times (with 95% CIs)\") +\n  geom_point(position = position_dodge(0.2), size = 2) +\n  geom_line(position = position_dodge(0.2), aes(group=tense)) +\n  geom_errorbar(aes(ymin=lower,ymax=upper), position = position_dodge(0.2), width = .2) +\n  theme_bw() +\n  theme(text = element_text(size=8))\n\n\n\n\n\n\nFigure 16.3: ?(caption)"
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "5  Data Visualisation with ggplot2",
    "section": "",
    "text": "6 Data communication\niris |&gt; \n  ggplot(aes(x=Sepal.Length)) +\n  geom_histogram() +\n  labs(title = \"A histogram\",\n       x = \"variable\")\niris |&gt; \n  ggplot(aes(x=Sepal.Length)) +\n  geom_density() +\n  labs(title = \"A density plot\",\n       x = \"variable\")\nNordmann et al. (2022)\nNordmann & DeBruine (2022)\nWickham et al. (n.d.), Chapter 2"
  },
  {
    "objectID": "data_viz.html#load-packages-and-data",
    "href": "data_viz.html#load-packages-and-data",
    "title": "5  Data Visualisation with ggplot2",
    "section": "6.1 Load packages and data",
    "text": "6.1 Load packages and data\n\n# load tidyverse\nlibrary(tidyverse)\n\n# load data\ndf_lifetime &lt;- readr::read_csv(here::here(\"data/tidy_data_lifetime_pilot.csv\"), \n                               # for special characters\n                               locale = readr::locale(encoding = \"latin1\") \n                               ) |&gt;\n  mutate_if(is.character,as.factor) |&gt; # all character variables as factor\n  filter(type == \"critical\", # only critical trials\n         px != \"px3\") # this participant had lots of 0's for some reason"
  },
  {
    "objectID": "data_viz.html#tables",
    "href": "data_viz.html#tables",
    "title": "5  Data Visualisation with ggplot2",
    "section": "6.2 Tables",
    "text": "6.2 Tables\n\nwe can create summaries of our data\n\n\n\nCode\n# compute summary \nsummary_ff &lt;- df_lifetime |&gt; \n  filter(region==\"verb\") |&gt; \n  group_by(condition,lifetime,tense) %&gt;%\n  summarise(N = n(),\n            mean.ff = mean(ff, na.rm = T),\n            sd = sd(ff, na.rm = T)) %&gt;%\n  # compute standard error, confidence intervals, and lower/upper ci bounds\n  mutate(se = sd / sqrt(N),\n         ci = qt(1 - (0.05 / 2), N - 1) * se,\n         lower.ci = mean.ff - qt(1 - (0.05 / 2), N - 1) * se,\n         upper.ci = mean.ff + qt(1 - (0.05 / 2), N - 1) * se)\n\n\n\nand print the output with the kable() function from the knitr package\n\nfor extra customisation you can also use the kableExtra package (e.g., with the kable_styling() function)\n\n\n\n# install.packages(\"knitr\") # if not yet installed\nknitr::kable(summary_ff, digits=1,\n             caption = \"Table with summmary statistics for first-fixation duration at the verb region\")\n\n\nTable with summmary statistics for first-fixation duration at the verb region\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncondition\nlifetime\ntense\nN\nmean.ff\nsd\nse\nci\nlower.ci\nupper.ci\n\n\n\n\ndeadPP\ndead\nPP\n140\n198.9\n57.9\n4.9\n9.7\n189.2\n208.6\n\n\ndeadSF\ndead\nSF\n139\n194.6\n67.9\n5.8\n11.4\n183.2\n205.9\n\n\nlivingPP\nliving\nPP\n140\n194.2\n77.3\n6.5\n12.9\n181.3\n207.1\n\n\nlivingSF\nliving\nSF\n140\n186.0\n57.6\n4.9\n9.6\n176.4\n195.6\n\n\n\n\n\n\n6.2.1 Exercise\n\ninstall the knitr package (install.packages(\"knitr\"))\ncreate an object with some summary statistics of the variable rt\n\n\ncall it summary_rt\n\n\nuse kable() from knitr to print a table\n\n\nknitr::kable(summary_rt, digits=1,\n             caption = \"Summary of reaction times (ms) per condition\")\n\n\nSummary of reaction times (ms) per condition\n\n\nlifetime\ntense\ncondition\nN\nmean.rt\nsd\n\n\n\n\ndead\nPP\ndeadPP\n140\n3530.5\n2915.8\n\n\ndead\nSF\ndeadSF\n139\n1747.0\n1153.4\n\n\nliving\nPP\nlivingPP\n140\n2257.7\n1346.3\n\n\nliving\nSF\nlivingSF\n140\n2578.1\n1958.7"
  },
  {
    "objectID": "data_viz.html#start-layering",
    "href": "data_viz.html#start-layering",
    "title": "5  Data Visualisation with ggplot2",
    "section": "9.1 Start layering",
    "text": "9.1 Start layering\n\ndf_lifetime |&gt; ggplot(aes(ff)) # aes = 'aesthetic'"
  },
  {
    "objectID": "data_viz.html#add-labels",
    "href": "data_viz.html#add-labels",
    "title": "5  Data Visualisation with ggplot2",
    "section": "9.2 Add labels",
    "text": "9.2 Add labels\n\ndf_lifetime |&gt; ggplot(aes(ff)) + \n  labs(title = \"Histogram of first fixation times\",\n       x = \"First fixation times (ms)\")"
  },
  {
    "objectID": "data_viz.html#add",
    "href": "data_viz.html#add",
    "title": "5  Data Visualisation with ggplot2",
    "section": "9.3 Add",
    "text": "9.3 Add\n\ndf_lifetime |&gt; ggplot(aes(ff)) + \n  labs(title = \"Histogram of first fixataion times\",\n       x = \"First fixation times (ms)\") +\n  geom_histogram()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds)"
  },
  {
    "objectID": "data_viz.html#add-condition",
    "href": "data_viz.html#add-condition",
    "title": "5  Data Visualisation with ggplot2",
    "section": "9.4 Add condition",
    "text": "9.4 Add condition\n\ndf_lifetime |&gt; ggplot(aes(ff, fill = condition)) + \n  labs(title = \"First fixataion times at the verb region\",\n       x = \"First fixation times (ms)\") +\n  geom_histogram()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds)\n\n\n\n\n\nThe colour here is STACKED!! i.e., not layered. Notice the distribution doesn’t change from all grey to coloured"
  },
  {
    "objectID": "data_viz.html#customisation",
    "href": "data_viz.html#customisation",
    "title": "5  Data Visualisation with ggplot2",
    "section": "9.5 Customisation",
    "text": "9.5 Customisation\n\nwe can add arguments to our geoms\n\ne.g., transparency: alpha = takes a value between 0 to 1\n\nwe can use theme() to customise font sizes, legend placement, etc.\ntehre are also popular preset themes, such as theme_bw() and theme_minimal()\n\n\ntheme_bw()theme_minimal()\n\n\n\ndf_lifetime |&gt; ggplot(aes(ff, fill = condition)) + \n  labs(title = \"Histogram of first fixataion times\",\n       x = \"First fixation times (ms)\") +\n  geom_histogram(alpha=.5) +\n  theme_bw()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds).\n\n\n\n\n\n\n\ndf_lifetime |&gt; ggplot(aes(ff, fill = condition)) + \n  labs(title = \"Histogram of first fixataion times\",\n       x = \"First fixation times (ms)\") +\n  geom_histogram(alpha=.5) +\n  theme_minimal()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds)."
  },
  {
    "objectID": "data_viz.html#density-plots",
    "href": "data_viz.html#density-plots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "10.1 Density plots",
    "text": "10.1 Density plots\n\nbelow I just replaced geom_histogram() with geom_density()\n\nI also filtered the data to include only values of ff above 0\n\nwhat is plotted along the y-axis? how does this differ from a histogram?\n\n\ndf_lifetime |&gt; \n  filter(ff &gt; 0) |&gt; \n  ggplot(aes(ff)) + \n  labs(title = \"Histogram of first fixataion times\",\n       x = \"First fixation times (ms)\") +\n  geom_density() +\n  theme_minimal()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds)."
  },
  {
    "objectID": "data_viz.html#grouped-density-plots",
    "href": "data_viz.html#grouped-density-plots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "10.2 Grouped density plots",
    "text": "10.2 Grouped density plots\n\njust like with histograms, we can look at the density plots of different subsets of the data with aes(fill = )\n\nlike region\n\n\n\ndf_lifetime |&gt; \n  filter(ff &gt; 0) |&gt; \n  ggplot(aes(ff, fill = region)) + \n  labs(title = \"Histogram of first fixataion times\",\n       x = \"First fixation times (ms)\") +\n  geom_density(alpha=.5) +\n  theme_minimal()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds).\n\n\n\n\n\n10.2.1 facet_grid()\n\nthere are a lot of overlapping density curves, let’s try to separate them with facet_grid(x~y)\n\n\ndf_lifetime |&gt; \n  filter(ff &gt; 0) |&gt; \n  ggplot(aes(ff, fill = region)) + \n  facet_grid(.~region) +\n  labs(title = \"Density plot of first fixataion times by region\",\n       x = \"First fixation times (ms)\") +\n  geom_density(alpha=.5) +\n  theme_bw()\n\n\n\n\nDistribution of first fixation times at the verb region (raw milliseconds).\n\n\n\n\n\nhow would you describe the density plots of the different regions?\n\n\n\n10.2.2 re-ordering factors\n\nby default, factors will be ordered alphabetically\n\nbut we don’t always want that\nhere, verb-1 should be before verb\n\n\n\ndf_lifetime &lt;- df_lifetime %&gt;%\n  mutate(region = factor(region, \n                         levels = c(\"verb-1\",\"verb\",\"verb+1\",\"verb+2\",\"verb+3\",\"verb+4\")))\n\nsummary(df_lifetime$region)\n\nverb-1   verb verb+1 verb+2 verb+3 verb+4 \n   559    559    559    559    559    182 \n\n\n\n10.2.2.1 Exercise\n\ncreate a density plot with the fill colour set to condition, but:\n\n\nsubset the data to only include the verb region\nyou can decide if you want to use facets or to have the density curves overlayed\nyour plot should look something like A or B:\n\n\n\n\n\n\n\n\n10.2.2.2 Extra exercise\n\nCan you produce these plots?"
  },
  {
    "objectID": "data_viz.html#scatterplots",
    "href": "data_viz.html#scatterplots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "10.3 Scatterplots",
    "text": "10.3 Scatterplots\n\nhistograms and density plots plot a single variable along the x-axis\n\nin most other plots the dependent (measure) variable is plotted along the y-axis by convention\n\nscatterplots plot the relationship between two variables\n\n\niris |&gt; \n  ggplot(aes(x=Sepal.Length, y=Sepal.Width)) +\n  geom_point() +\n  labs(title = \"A scatterplot\",\n       x = \"variable X\",\n       y = \"variable Y\")\n\n\n\n\n\n10.3.1 Scatterplots\n\nthe figure below plots total reading times (verb region) to the verb region (x-axis) and reaction times to the critical sentence (y-axis)\n\nwhat does each point represent?\nhow would you describe the relationship between the two variables?\n\n\n\ndf_lifetime |&gt;\n  filter(ff &gt; 0,\n         region == \"verb\") |&gt;\n  ggplot(aes(x = tt, y = rt)) +\n  labs(title = \"Scatter plot of total reading times (verb region)\nand reaction times (critical sentence)\",\n       x = \"Total reading time (ms)\",\n       y = \"Reaction time (ms)\") +\n  geom_point(alpha = .2) +\n  theme_bw()\n\n\n\n\n\n10.3.1.1 Exercise\n\nGenerate a scatterplot of total reading times and reaction times, with:\n\ncolour and shape set to condition\ntip: these both belong in aes()\n\nWhat information does this plot suggest?"
  },
  {
    "objectID": "data_viz.html#boxplots",
    "href": "data_viz.html#boxplots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "11.1 Boxplots",
    "text": "11.1 Boxplots\n\nboxplots provide information about the distribution of a continuous variable\n\nbut includes information like median (dark line) and quartiles (box and whiskers)\nand outliers (dots)\n\nlike scatterplots, require x and y variables\n\nbut one of them needs to be categorical\n\n\n\niris |&gt; \n  ggplot(aes(x = Species, y = Sepal.Length)) +\n  labs(title = \"A scatterplot\",\n       x = \"Categorical variable\",\n       y = \"Continuous variable\") +\n  geom_boxplot()\n\n\n\n\nA scatterplot. Median (50th percentile): thick black lines; interquartile range (IQR; 25th and 75th percentile): box limits; minimum (0th percentile) and maximum (100th percentile) excluding outliers: : whiskers; outliers: points"
  },
  {
    "objectID": "data_viz.html#boxplot-explained",
    "href": "data_viz.html#boxplot-explained",
    "title": "5  Data Visualisation with ggplot2",
    "section": "11.2 Boxplot explained",
    "text": "11.2 Boxplot explained\n\n\n\n\n\nImage source: (winter_statistics_2019?) (all rights reserved)"
  },
  {
    "objectID": "data_viz.html#boxplots-1",
    "href": "data_viz.html#boxplots-1",
    "title": "5  Data Visualisation with ggplot2",
    "section": "11.3 Boxplots",
    "text": "11.3 Boxplots\n\nlet’s change our scatterplot to a boxplot\n\n\ndf_lifetime |&gt;\n  filter(ff &gt; 0,\n         region == \"verb\") |&gt;\n  ggplot(aes(x = tense, y = ff)) +\n  labs(title = \"First-fixation duration (verb region)\",\n       x = \"Tense\",\n       y = \"First-fixation duration (ms)\") +\n  geom_boxplot(alpha = .2) +\n  theme_bw()\n\n\n\n\n\n11.3.1 Grouped boxplots\n\ndf_lifetime |&gt;\n  filter(ff &gt; 0,\n         region == \"verb\") |&gt;\n  ggplot(aes(x = tense, y = ff, colour = lifetime)) +\n  labs(title = \"First-fixation duration (verb region)\",\n       x = \"Tense\",\n       y = \"First-fixation duration (ms)\") +\n  geom_boxplot(alpha = .2) +\n  theme_bw()\n\n\n\n\n\n11.3.1.1 Exercise\n\nCreate a group boxplot (x = tense, fill = lifetime) for\n\n\nfirst-pass reading time (verb region)\nregression path duration (verb region)\ntotal reading time (verb region)\nreaction times (use the distinct() verb to have a single observation per participant and per trial)"
  },
  {
    "objectID": "data_viz.html#violin-plots",
    "href": "data_viz.html#violin-plots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "11.4 Violin plots",
    "text": "11.4 Violin plots"
  },
  {
    "objectID": "data_viz.html#violin-boxplots",
    "href": "data_viz.html#violin-boxplots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "11.5 Violin boxplots",
    "text": "11.5 Violin boxplots"
  },
  {
    "objectID": "data_viz.html#interaction-plots",
    "href": "data_viz.html#interaction-plots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "12.1 Interaction plots",
    "text": "12.1 Interaction plots\n\n\n\ncommon for factorial designs, i.e., comparing categorical predictors\nthere are 2 ways of producing them:\n\nwith your data frame and stat_summary()\nor with a summary table and ggplot geoms geom_point(), geom_errorbar(), and geom_line()\n\nwe’ll need our summary table to plot an interaction plot\n\n\n\n\n\n\n\ncondition\nlifetime\ntense\nN\nmean.ff\nsd\nse\nci\nlower.ci\nupper.ci\n\n\n\n\ndeadPP\ndead\nPP\n140\n198.9\n57.9\n4.9\n9.7\n189.2\n208.6\n\n\ndeadSF\ndead\nSF\n139\n194.6\n67.9\n5.8\n11.4\n183.2\n205.9\n\n\nlivingPP\nliving\nPP\n140\n194.2\n77.3\n6.5\n12.9\n181.3\n207.1\n\n\nlivingSF\nliving\nSF\n140\n186.0\n57.6\n4.9\n9.6\n176.4\n195.6"
  },
  {
    "objectID": "data_viz.html#bar-plot",
    "href": "data_viz.html#bar-plot",
    "title": "5  Data Visualisation with ggplot2",
    "section": "13.1 Bar plot",
    "text": "13.1 Bar plot\n\n\nbe sure to read in accept as a factor!\n\n\n\n\ndf_lifetime |&gt; \n  distinct(px,trial,.keep_all=T) |&gt; \n  ggplot(aes(x = as.factor(accept) )) +\n  geom_bar() +\n  theme_bw()\n\n\n\n\n\n\n\ndf_lifetime |&gt; \n  distinct(px,trial,.keep_all=T) |&gt; \n  ggplot(aes(x = as.factor(accept), fill = condition)) +\n  labs(title = \"Binary responses\",\n       x = \"Naturalness response\",\n       fill = \"Condition\") +\n  geom_bar() +\n  theme_bw()"
  },
  {
    "objectID": "data_viz.html#grouped-bar-plots",
    "href": "data_viz.html#grouped-bar-plots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "13.2 Grouped bar plots",
    "text": "13.2 Grouped bar plots\n\ndf_lifetime |&gt; \n  distinct(px,trial,.keep_all=T) |&gt; \n  ggplot(aes(x = as.factor(accept), fill = condition)) +\n  labs(title = \"Binary responses\",\n       x = \"Naturalness response\",\n       fill = \"Condition\") +\n  geom_bar(position = \"dodge\") +\n  theme_bw()\n\n\n\n\n\n13.2.1 Exercise\n\nGenerate a grouped bar plot (i.e., dodge) with:\n\na facet grid for tense\nplots lifetime on the x-axis\nand fills the bars based on accept\nchange the labels accordingly\ncustomise as you like\n\n\n\ndf_lifetime |&gt; \n  distinct(px,trial,.keep_all=T) |&gt; \n  ggplot(aes(x = lifetime, fill = as.factor(accept))) +\n  facet_grid(.~tense) +\n  labs(title = \"Binary responses\",\n       x = \"Lifetime\",\n       fill = \"Response\") +\n  geom_bar(position = \"dodge\") +\n  theme_bw()"
  },
  {
    "objectID": "data_viz.html#grouped-bar-plots-1",
    "href": "data_viz.html#grouped-bar-plots-1",
    "title": "5  Data Visualisation with ggplot2",
    "section": "13.3 Grouped bar plots",
    "text": "13.3 Grouped bar plots\n\ndf_lifetime |&gt; \n  distinct(px,trial,.keep_all=T) |&gt; \n  ggplot(aes(x = lifetime, fill = as.factor(accept))) +\n  facet_grid(.~tense) +\n  labs(title = \"Grouped and faceted barplot\",\n       x = \"Lifetime\",\n       fill = \"Response\") +\n  geom_bar(position = \"dodge\") +\n  theme_bw()"
  },
  {
    "objectID": "data_viz.html#stacked-bar-plots",
    "href": "data_viz.html#stacked-bar-plots",
    "title": "5  Data Visualisation with ggplot2",
    "section": "13.4 Stacked bar plots",
    "text": "13.4 Stacked bar plots\n\ndf_lifetime |&gt; \n  distinct(px,trial,.keep_all=T) |&gt; \n  ggplot(aes(x = lifetime, fill = as.factor(accept))) +\n  facet_grid(.~tense) +\n  labs(title = \"Stacked and faceted barplot\",\n       x = \"Lifetime\",\n       fill = \"Response\") +\n  geom_bar(position = \"stack\") +\n  theme_bw()\n\n\n\n\n\n13.4.1 Exercise\n\nChoose the barplot you like best for binary data\nReproduce that barplot, but with reg_in at the verb1 region\n\n\n\n\n\n\n\n\n13.4.2 Extra exercise\n\nCreate another bar plot, but for reg_out for all sentence regions\nUse facet_grid()\n\n\nto have facets by region (columns) and by tense (in 2 rows)"
  },
  {
    "objectID": "lin_reg1.html",
    "href": "lin_reg1.html",
    "title": "6  Linear Regression 1",
    "section": "",
    "text": "Learning Objectives\nToday we will learn…\nMake sure you start with a clean R Environment (Session &gt; Restart R).\n(debruine_understanding_2021?); (winter_linear_2013?); (winter_very_2014?); (winter_statistics_2019?)\n\\[\nfp \\sim lifetime\n\\]\nCode\n# position_jitter\npj &lt;- position_jitter(0.2)\n\n# plot\ndf_crit_verb %&gt;% \n  filter(region==\"verb\") %&gt;% \n  ggplot(aes(x = lifetime, y = fp, colour = lifetime)) +\n  geom_point(position = pj) +\n  theme(legend.position = \"none\") +\n  theme_bw()\nImage source: (winter_statistics_2019?) (all rights reserved)\nNow it’s your turn. Try to run the following lm() models:\nCode\nsessionInfo()\n\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] magick_2.7.4     kableExtra_1.3.4 knitr_1.43       patchwork_1.1.2 \n [5] broom_1.0.5      lubridate_1.9.2  forcats_1.0.0    stringr_1.5.0   \n [9] dplyr_1.1.2      purrr_1.0.1      readr_2.1.4      tidyr_1.3.0     \n[13] tibble_3.2.1     ggplot2_3.4.2    tidyverse_2.0.0 \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      xfun_0.39         htmlwidgets_1.6.2 rstatix_0.7.2    \n [5] lattice_0.21-8    tzdb_0.4.0        vctrs_0.6.3       tools_4.3.0      \n [9] generics_0.1.3    parallel_4.3.0    fansi_1.0.4       highr_0.10       \n[13] pacman_0.5.1      pkgconfig_2.0.3   Matrix_1.5-4      webshot_0.5.5    \n[17] lifecycle_1.0.3   farver_2.1.1      compiler_4.3.0    munsell_0.5.0    \n[21] carData_3.0-5     htmltools_0.5.5   yaml_2.3.7        car_3.1-2        \n[25] ggpubr_0.6.0      pillar_1.9.0      crayon_1.5.2      abind_1.4-5      \n[29] nlme_3.1-162      tidyselect_1.2.0  rvest_1.0.3       digest_0.6.33    \n[33] stringi_1.7.12    splines_4.3.0     labeling_0.4.2    cowplot_1.1.1    \n[37] rprojroot_2.0.3   fastmap_1.1.1     grid_4.3.0        here_1.0.1       \n[41] colorspace_2.1-0  cli_3.6.1         magrittr_2.0.3    utf8_1.2.3       \n[45] withr_2.5.0       scales_1.2.1      backports_1.4.1   bit64_4.0.5      \n[49] timechange_0.2.0  rmarkdown_2.23    httr_1.4.6        bit_4.0.5        \n[53] ggsignif_0.6.4    hms_1.1.3         evaluate_0.21     viridisLite_0.4.2\n[57] mgcv_1.8-42       rlang_1.1.1       Rcpp_1.0.11       glue_1.6.2       \n[61] xml2_1.3.5        renv_0.17.3       svglite_2.1.1     rstudioapi_0.15.0\n[65] vroom_1.6.3       jsonlite_1.8.7    R6_2.5.1          systemfonts_1.0.4"
  },
  {
    "objectID": "lin_reg1.html#load-packages",
    "href": "lin_reg1.html#load-packages",
    "title": "6  Linear Regression 1",
    "section": "Load packages",
    "text": "Load packages\n\n# suppress scientific notation\noptions(scipen=999)\n\n\n# load libraries\npacman::p_load(tidyverse,\n               broom,\n               patchwork,\n               knitr,\n               kableExtra)"
  },
  {
    "objectID": "lin_reg1.html#load-in-data",
    "href": "lin_reg1.html#load-in-data",
    "title": "6  Linear Regression 1",
    "section": "Load in data",
    "text": "Load in data\n\nforce character variables to factors\nfilter for the verb region from critical items only, remove participant 3, and remove values of first-fixtation that are 0\n\n\n# load in dataset\ndf_crit_verb &lt;-\n  readr::read_csv(\n    here::here(\"data/tidy_data_lifetime_pilot.csv\"),\n    # for special characters\n    locale = readr::locale(encoding = \"latin1\")\n  ) |&gt;\n  mutate_if(is.character, as.factor) |&gt; # all character variables as factor\n  # mutate(lifetime = fct_relevel(lifetime, \"living\", \"dead\"),\n  #        tense = fct_relevel(tense, \"PP\", \"SF\")) |&gt;\n  filter(type == \"critical\", # only critical trials\n         px != \"px3\", # px3 had a lot of missing values\n         fp &gt; 0, # only values of fp above 0\n         region == \"verb\") %&gt;% # critical region only\n  droplevels() # remove any factor levels with no observations"
  },
  {
    "objectID": "lin_reg1.html#types-of-regression",
    "href": "lin_reg1.html#types-of-regression",
    "title": "6  Linear Regression 1",
    "section": "8.1 Types of regression",
    "text": "8.1 Types of regression\n\n\n\n\n\nregression type\npredictor\noutcome\n\n\n\n\nsimple regression\nSingle predictor\ncontinuous (numerical)\n\n\nmultiple regression\nmultiple predictor\ncontinuous (numerical)\n\n\nhierarchical/linear mixed models/linear mixed effect models\ninclude random effect\ncontinuous (numerical)\n\n\ngeneralised linear (mixed) models/logistic regression\nas above\nbinary/binomial data or count data"
  },
  {
    "objectID": "lin_reg1.html#straight-lines",
    "href": "lin_reg1.html#straight-lines",
    "title": "6  Linear Regression 1",
    "section": "8.2 Straight lines",
    "text": "8.2 Straight lines\n\nlinear regression summarises the data with a straight line\n\nwe model our data as/fit our data to a straight line\n\nstraight lines can be defined by\n\nIntercept (\\(b_0\\))\n\nvalue of \\(Y\\) when \\(X = 0\\)\n\nSlope (\\(b_1\\))\n\ngradient (slope) of the regression line\ndirection/strength of relationship between \\(x\\) and \\(y\\)\nregression coefficient for the predictor\n\n\nso we need to define an intercept and a slope\n\n\n8.2.1 A line = intercept and slope\n\na line is defined by its intercept and slope\n\nin a regression model, these two are called coefficients\n\n\n\n\n\n\n\nImage source: (winter_statistics_2019?) (all rights reserved)\n\n\n\n\n\n\n8.2.2 Intercept (\\(b_0\\))\n\nthe value of \\(y\\) when \\(x = 0\\)\n\n\n\n\n\n\n\n\n8.2.3 Slopes (\\(b_1\\))\n\n\n\nslopes describe a change in \\(x\\) (\\(\\Delta x\\)) over a change in \\(y\\) (\\(\\Delta y\\))\n\npositive slope: as \\(x\\) increases, \\(y\\) increases\nnegative slope: as \\(x\\) increases, \\(y\\) decreases\nif the slope is 0, there is no change in \\(y\\) as a function of \\(x\\)\n\nor: the change in \\(y\\) when \\(x\\) increase by 1 unit\n\nsometimes referred to as “rise over run”: how do you ‘rise’ in \\(y\\) for a given ‘run’ in \\(x\\)?\n\n\n\n\\[\nslope = \\frac{\\Delta x}{\\Delta y}\n\\]\n\n\n\n\n\nwhat is the intercept of this line?\nwhat is the slope of this line?\n\n\n\n\n\n\n\n\n\n\n\n8.2.4 Error and residuals\n\nfixed effects (IV/predictors): things we can understand/measure\nerror (random effects): things we cannot understand/measure\n\nin biology, social sciences (and linguistic research), there will always sources of random error that we cannot account for\nrandom error is less an issue in e.g., physics (e.g., measuring gravitational pull)\n\nresiduals: the difference (vertical difference) between observed data and the fitted values (predicted values)\n\n\n\n\n\n\n\n\n\n\nEquation of a line\n\n\n\n\\[\n\\begin{align}\ny & = mx + c\\\\\nY_i &= (b_0 + b_1X_i) + \\epsilon_i\\\\\noutcome_i & = (model) + error_i\\\\\ny_i & = (intercept + slope*x_i) + error_i\n\\end{align}\n\\]"
  },
  {
    "objectID": "lin_reg1.html#method-of-least-squares",
    "href": "lin_reg1.html#method-of-least-squares",
    "title": "6  Linear Regression 1",
    "section": "8.3 Method of least squares",
    "text": "8.3 Method of least squares\n\nso how is any given line chosen to fit any given data?\nthe method of least squares\n\ntake a given line, and square all the residuals (i.e., \\(residual^2\\))\nthe line with the lowest sum of squares is the line with the best fit to the given data\nwhy do we square the residuals before summing them up?\n\nso all values are positive (i.e., so that negative values don’t cancel out positive values)\n\n\nthis is how we find the line of best fit\n\nR fits many lines to find the one with the best fit\n\n\n\n\n\n\n\n\nFigure 8.1: Observed values (A), Residuals for line of best fit (B), A line of worse fit with larger residuals (C)"
  },
  {
    "objectID": "lin_reg1.html#lm",
    "href": "lin_reg1.html#lm",
    "title": "6  Linear Regression 1",
    "section": "9.1 lm()",
    "text": "9.1 lm()\n\nthe lm() function fits simple linear models\n\nas arguments it takes a formula and a dataset, at minimum\n\n\n\\[\nlm(outcome \\sim 1 + predictor,\\;data\\;=\\;df\\_name)\n\\]\n\nlm() function formula syntax can be read as: fp predicted by the intercept (1 is a placeholder for the intercept)\n\nthe intercept is included by default\nif you omit the 1, the intercept is still included in the formula\nif you wanted to remove the intercept (which you often don’t), you could replace 1 with 0\n\n\n\n9.1.1 Running a model\n\nbefore we add our predictor lifetime, let’s see what our model looks like without it\n\n\nfit_fp_1 &lt;- lm(fp ~ 1, data = df_crit_verb) \n\n\n\n9.1.2 Model ouput\n\nprinting just the model gives us the formula and the coefficients\n\n\nfit_fp_1\n\n\nCall:\nlm(formula = fp ~ 1, data = df_crit_verb)\n\nCoefficients:\n(Intercept)  \n      309.2  \n\n\n\nrecall that the intercept and slope are called coefficients\n\nwhy do we only see Intercept?\n\n\n\n\nwe typically use the summary() function to print full model outputs\n\n\nsummary(fit_fp_1)\n\n\nCall:\nlm(formula = fp ~ 1, data = df_crit_verb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-227.17 -106.17  -26.17   65.83  761.83 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)   309.17       6.29   49.15 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 146.6 on 542 degrees of freedom\n\n\n\n\n\n\n\n\n\nbroom package\n\n\n\n\nthe broom package has some useful functions for printing model outputs\n\ntidy() produces a tibble (type of dataframe) of the coefficients\nglance() produces goodness of fit measures (which we won’t discuss)\n\nthe outputs from tidy() and glance() can be fed into kable and/or kable_styling() to create formatted tables\n\n\ntidy(fit_fp_1)\n\n# A tibble: 1 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     309.      6.29      49.2 7.03e-202\n\n\n\nglance(fit_fp_1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         0             0  147.        NA      NA    NA -3478. 6960. 6969.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\naugment() adds model values as columns to your dataframe (e.g., useful for plotting observed vs. fitted values)\n\n\naugment(fit_fp_1, data = df_crit_verb) %&gt;% summary()\n\n\n\n\n\n9.1.3 Interpreting model output\n\nlet’s take a closer look at our model summary\n\n\nsummary(fit_fp_1)\n\n\nCall:\n1lm(formula = fp ~ 1, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n2-227.17 -106.17  -26.17   65.83  761.83\n\nCoefficients:\n3            Estimate Std. Error t value            Pr(&gt;|t|)\n4(Intercept)   309.17       6.29   49.15 &lt;0.0000000000000002 ***\n---\n5Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n6Residual standard error: 146.6 on 542 degrees of freedom\n\n\n1\n\nformula repetition\n\n2\n\nresiduals: differences between observed values and those predicted by the model\n\n3\n\nnames for columns Estimates, standard error, t-value, p-value (Pr(&gt;|t|))\n\n4\n\nIntercept (\\(b_0\\)), i.e., value of \\(y\\) (first-pass) with a move of one unit of \\(x\\) (lifetime)\n\n5\n\nSignificance codes\n\n6\n\nR\\(^2\\), a measure of model fit (squared residuals); percentage of variance in the data shared with the predictor (higher numbers are better…this is pretty low)\n\n\n\n\n\n\n9.1.4 Intercept\n\nour intercept is roughly 309.2 milliseconds; what does this number represent?\n\nthe intercept is essentially the mean\n\n\n\n# print model intercept?\ncoef(fit_fp_1)['(Intercept)']\n\n(Intercept) \n   309.1713 \n\n\n\n# print data mean\nmean(df_crit_verb$fp)\n\n[1] 309.1713\n\n\n\n9.1.4.1 Intercept significance\n\nin the output, the intercept seems to be significant (indicated with a low p-value, and ***)\n\nwhat does this mean?\n\nsignificance pretty much tells us if a number is equal to (or not statistically significantly different from) 0\n\nso this tells us that the intercept (i.e., the mean first-pass reading time at the verb region) is different from 0\nmost of the time, this isn’t interesting or even theoretically relevant\n\nthe larger your t-value, the smaller your p-value\n\n\n\n\n\n\n\n\nA word on t-values and p-values\n\n\n\nt-values quantify the difference between population means.\np-values quantify the probability of obtaining a result equal to or greater than what was observed, given the assumption of no effect (the null hypothesis).\nIf the null hypothesis were true, we would expect no effect (a flat line). If we have a lot of evidence/are confidence that there is an effect (the line (slope) is in fact not flat), then it would be unlikely that we would find such a result under the assumption that there is no effect (the line actually is flat) i.e., the null hypothesis. This is reflected in a small p-value.\n\n\n\n\n\n9.1.5 Plotting fp ~ 1\n\nFigure 9.1 shows the intercept (red dot) amongst the observed data (black dots)\n\nalong the x-axis we have abstract numerical units (the values don’t mean anything)\nwhat would the values of the intercept be?\n\n\n\n\n\n\n\nFigure 9.1: Visualisation of ‘fp ~ 1’: observed values (black) and mean (intercept; red). Residuals would be the distance from each black dot to the y-value of the read dot"
  },
  {
    "objectID": "lin_reg1.html#adding-a-fixed-effect-slope",
    "href": "lin_reg1.html#adding-a-fixed-effect-slope",
    "title": "6  Linear Regression 1",
    "section": "9.2 Adding a fixed effect (slope)",
    "text": "9.2 Adding a fixed effect (slope)\n\nnow let’s include a slope\nthe slope represents the change in \\(y\\) (DV: fp) when we move 1-unit along \\(y\\) (IV: lifetime)\nin other words, it tells us the effect our IV has on the DV\n\nwhat is the change in first-pass reading times when we move from dead to living referents?\n\nlifetime is categorical, how can we move 1 unit?\n\na linear model requires \\(x\\) and \\(y\\) to be numerical, so it simply codes factor levels as 0 and 1 by default (in alphabetical order)\nso the slope represents the difference between categorical conditions"
  },
  {
    "objectID": "lin_reg1.html#fit-model-treatment-contrasts",
    "href": "lin_reg1.html#fit-model-treatment-contrasts",
    "title": "6  Linear Regression 1",
    "section": "9.3 Fit model (treatment contrasts)",
    "text": "9.3 Fit model (treatment contrasts)\n\n# fit simple linear model\nfit_fp_lifetime_treat &lt;- df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;%\n  lm(fp ~ lifetime, data = .)\n\n\n# alternatively\nfit_fp_lifetime_treat &lt;- lm(fp ~ lifetime, \n            data = df_crit_verb, subset = fp &gt; 0)\n\n\n9.3.1 Model summary\n\nsummary(fit_fp_lifetime_treat)\n\n\nCall:\nlm(formula = fp ~ lifetime, data = df_crit_verb, subset = fp &gt; \n    0)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-228.99 -109.29  -26.99   58.86  777.71 \n\nCoefficients:\n               Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)     324.993      8.843  36.752 &lt;0.0000000000000002 ***\nlifetimeliving  -31.701     12.517  -2.533              0.0116 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 145.8 on 541 degrees of freedom\nMultiple R-squared:  0.01172,   Adjusted R-squared:  0.00989 \nF-statistic: 6.414 on 1 and 541 DF,  p-value: 0.0116\n\n\n\n\n9.3.2 Intercept\n\n# print model intercept?\ncoef(fit_fp_lifetime_treat)['(Intercept)']\n\n(Intercept) \n   324.9926 \n\n\n\n# print data mean\nmean(df_crit_verb$fp)\n\n[1] 309.1713\n\n\n\nour intercept is no longer the grand mean of first-pass reading times…what is it?\n\n\n\n9.3.3 Intercept for treatment contrasts\n\n\n\nwhat are the means of our two factor levels?\n\n\n# print model intercept?\ncoef(fit_fp_lifetime_treat)['(Intercept)']\n\n(Intercept) \n   324.9926 \n\n\n\n\n\nCode\n# compute summary \nsummary_ff_life &lt;- df_crit_verb |&gt; \n  filter(region==\"verb\",\n         fp &gt; 0) |&gt; \n  group_by(lifetime) %&gt;%\n  summarise(N = n(),\n            mean = mean(fp, na.rm = T),\n            sd = sd(fp, na.rm = T))\n\nknitr::kable(summary_ff_life, digits=3,\n             caption = \"Summmary statistics for first-pass reading times at the verb region\") %&gt;% \n  kableExtra::kable_styling(font_size = 30,\n                            position = \"left\")\n\n\n\nSummmary statistics for first-pass reading times at the verb region\n\n\nlifetime\nN\nmean\nsd\n\n\n\n\ndead\n272\n324.993\n151.005\n\n\nliving\n271\n293.292\n140.468\n\n\n\n\n\n\n\n\n\n\n\n9.3.4 Slope\n\n\n\nwhat was our slope?\nwhat does this correspond to?\n\n\n# print model intercept?\ncoef(fit_fp_lifetime_treat)['lifetimeliving']\n\nlifetimeliving \n     -31.70113 \n\n\n\n\n\nCode\n# compute summary \nsummary_ff_life &lt;- df_crit_verb |&gt; \n  filter(region==\"verb\",\n         fp &gt; 0) |&gt; \n  group_by(lifetime) %&gt;%\n  summarise(N = n(),\n            mean = mean(fp, na.rm = T),\n            sd = sd(fp, na.rm = T))\n\nknitr::kable(summary_ff_life, digits=3,\n             caption = \"Summmary statistics for first-pass reading time at the verb region\") %&gt;% \n  kableExtra::kable_styling(font_size = 30,\n                            position = \"left\")\n\n\n\nSummmary statistics for first-pass reading time at the verb region\n\n\nlifetime\nN\nmean\nsd\n\n\n\n\ndead\n272\n324.993\n151.005\n\n\nliving\n271\n293.292\n140.468\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhat was our slope?\nwhat does this correspond to?\n\n\n\n\n\n\n\nliving\ndead\ndiff\n\n\n\n\n293.2915\n324.9926\n-31.70113\n\n\n\n\n\n\n\n\n\n\nCode\n# compute summary \nsummary_ff_life &lt;- df_crit_verb |&gt; \n  filter(region==\"verb\",\n         fp &gt; 0) |&gt; \n  group_by(lifetime) %&gt;%\n  summarise(N = n(),\n            mean = mean(fp, na.rm = T),\n            sd = sd(fp, na.rm = T))\n\nknitr::kable(summary_ff_life, digits=3,\n             caption = \"Summmary statistics for first-pass reading time at the verb region\") %&gt;% \n  kableExtra::kable_styling(font_size = 30,\n                            position = \"left\")\n\n\n\nSummmary statistics for first-pass reading time at the verb region\n\n\nlifetime\nN\nmean\nsd\n\n\n\n\ndead\n272\n324.993\n151.005\n\n\nliving\n271\n293.292\n140.468"
  },
  {
    "objectID": "lin_reg1.html#ordering-our-contrasts",
    "href": "lin_reg1.html#ordering-our-contrasts",
    "title": "6  Linear Regression 1",
    "section": "10.1 Ordering our contrasts",
    "text": "10.1 Ordering our contrasts\n\nbut recall that we expected to find longer reading times for the dead condition\nso the living condition is conceptually a baseline, to which we are comparing a violation condition\nit typically makes sense to order your factors in an order that makes the slope easy to interpret\n\nwe would like a positive slope to indicate longer reading times for our violation condition\nso we should have living coded as 0, rather than dead\n\nlet’s order our predictor\n\nwe predict longer reading times for dead versus living, so order living-dead\n\n\n\n# order factor levels\ndf_crit_verb$lifetime &lt;- factor(df_crit_verb$lifetime, levels = c(\"living\",\"dead\"))\n\n\nnow what will our contrasts be?\n\n\ncontrasts(df_crit_verb$lifetime)\n\n       dead\nliving    0\ndead      1"
  },
  {
    "objectID": "lin_reg1.html#changing-our-contrasts-sum-coding",
    "href": "lin_reg1.html#changing-our-contrasts-sum-coding",
    "title": "6  Linear Regression 1",
    "section": "10.2 Changing our contrasts: sum coding",
    "text": "10.2 Changing our contrasts: sum coding\n\nnow that we know the order of our contrasts, we can also centre our predictor\n\nwe do this because it sometimes makes more sense for the intercept to represent the grand mean rather than the mean of one condition (this is especially true when interpreting interactions)\nto do this, we want 0 to be between our two factor levels\ne.g., change the contrasts to -0.5 and +0.5\nfor categorical variables, this is called sum coding\n\n\n\n# set contrasts\ncontrasts(df_crit_verb$lifetime) &lt;- c(-0.5,+0.5)\n\n\n# print contrasts\ncontrasts(df_crit_verb$lifetime)\n\n       [,1]\nliving -0.5\ndead    0.5\n\n\n\n\n\n\n\n\n\nCentring continuous predictors\n\n\n\nN.B., you would usually also centre numeric predictors. This is done by subtracting some constant from every value (usually by subtracting the mean of the predictor from each value and saving this as a new variable:\n\ndf_example %&gt;% \n  mutate(predictor_c &lt;- predictor-mean(predictor)\n\nIf you have interval data with a specific upper and lower bound, you could alternatively subtract the median value."
  },
  {
    "objectID": "lin_reg1.html#fit-model-sum-contrasts",
    "href": "lin_reg1.html#fit-model-sum-contrasts",
    "title": "6  Linear Regression 1",
    "section": "10.3 Fit model (sum contrasts)",
    "text": "10.3 Fit model (sum contrasts)\n\nnow let’s fit our model with sum contrasts\n\nthe syntax is exactly the same (as long as you didn’t create a new variable to store the sum coding, as some people do)\n\n\n\n# fit simple linear model\nfit_fp_lifetime_sum &lt;- df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;%\n  lm(fp ~ lifetime, data = .)\n\n\n10.3.1 Coefficients table with summary()\n\n\n&gt; summary(fit_fp_lifetime_sum)\n\nCall:\n1lm(formula = fp ~ lifetime, data = df_crit_verb, subset = fp &gt; 0)\n\n2Residuals:\n    Min      1Q  Median      3Q     Max \n-228.99 -109.29  -26.99   58.86  777.71 \n\nCoefficients:\n3             Estimate Std. Error t value Pr(&gt;|t|)\n4(Intercept)  309.142      6.259  49.394 &lt;0.0000000000000002 ***\n5lifetime1     31.701     12.517   2.533              0.0116 *\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 57.46 on 541 degrees of freedom\n6Multiple R-squared:  0.01172,   Adjusted R-squared:  0.00989\nF-statistic: 6.414 on 1 and 541 DF,  p-value: 0.0116\n\n\n1\n\nformula\n\n2\n\nResiduals: differences between observed values and those predicted by the model\n\n3\n\nNames for columns Estimates, SE, t-value, p-value\n\n4\n\nIntercept (\\(b_0\\)), i.e., value of \\(y\\) (first-pass) with a move of one unit of \\(x\\) (lifetime)\n\n5\n\nSlope (\\(b_1\\)), i.e., change in first fixation going from dead to living\n\n6\n\nOutput from an ANOVA\n\n\n\n\n\n\n\nwhat is the intercept?\nis the slope positive or negative?\n\nwhat is it’s value?\n\nthis is what the slope would look like:\n\n\n\n\n10.3.2 Understanding the summary\n\n\n\nlet’s compute summary statistics based on lifetime\n\nthen compare this to the model output\n\n\nExercises\n\nSubtract the mean first-pass reading time of dead from that of living\n\nwhat does this correspond to in the model summary?\n\nCompute the mean of dead+living\n\nwhat does this correspond to in the model summary?\n\nDivide the slope in 2. Subtract this from the mean of dead.\n\nwhat does this correspond to?\n\n\n\nSummary statistics\n\n\nCode\n# compute summary \nsummary_fp_life &lt;- df_crit_verb |&gt; \n  filter(region==\"verb\",\n         fp &gt; 0) |&gt; \n  group_by(lifetime) %&gt;%\n  summarise(N = n(),\n            mean = mean(fp, na.rm = T),\n            sd = sd(fp, na.rm = T)) %&gt;%\n  # compute standard error, confidence intervals, and lower/upper ci bounds\n  mutate(se = sd / sqrt(N),\n         ci = qt(1 - (0.05 / 2), N - 1) * se,\n         lower.ci = mean - qt(1 - (0.05 / 2), N - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), N - 1) * se)\n\nknitr::kable(summary_ff_life, digits=3,\n             caption = \"Summmary statistics for first-pass reading time at the verb region\") %&gt;% \n  kableExtra::kable_styling(font_size = 24,\n                            position = \"left\")\n\n\n\nSummmary statistics for first-pass reading time at the verb region\n\n\nlifetime\nN\nmean\nsd\n\n\n\n\ndead\n272\n324.993\n151.005\n\n\nliving\n271\n293.292\n140.468\n\n\n\n\n\n\n\nModel summary\n\nsummary(fit_fp_lifetime_sum)\n\n\nCall:\nlm(formula = fp ~ lifetime, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-228.99 -109.29  -26.99   58.86  777.71 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)  309.142      6.259  49.394 &lt;0.0000000000000002 ***\nlifetime1     31.701     12.517   2.533              0.0116 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 145.8 on 541 degrees of freedom\nMultiple R-squared:  0.01172,   Adjusted R-squared:  0.00989 \nF-statistic: 6.414 on 1 and 541 DF,  p-value: 0.0116"
  },
  {
    "objectID": "lin_reg1.html#comparing-contrasts",
    "href": "lin_reg1.html#comparing-contrasts",
    "title": "6  Linear Regression 1",
    "section": "10.4 Comparing contrasts",
    "text": "10.4 Comparing contrasts\n\nintercept = value of \\(y\\) when \\(x = 0\\)\ntreatment contrasts: factor levels are coded as 0 and 1\n\nintercept is mean of level that is coded as 0\n\nsum contrast coding: factor levels are coded as +/-0.5 (or 1)\n\nwhen \\(x = 0\\), this is the mid-way point between our two predictor levels\nso the intercept will be the grand mean of our two levels\n\nour slope is unchanged, however (unless we set our sum contrasts to +/- 1, which some people do)\n\n\n\n\n\n\n\nFigure 10.1: Comparison of contrast types"
  },
  {
    "objectID": "lin_reg1.html#exploring-the-model",
    "href": "lin_reg1.html#exploring-the-model",
    "title": "6  Linear Regression 1",
    "section": "Exploring the model",
    "text": "Exploring the model\n\n# how many observed values did we enter into the model?\ndf_crit_verb |&gt; \n  filter(fp &gt; 0) |&gt; \n  nrow()\n\n[1] 543\n\n\n\n# how many observed values did we enter into the model?\nlength(fitted(fit_fp_lifetime_sum))\n\n[1] 543"
  },
  {
    "objectID": "lin_reg1.html#exploring-the-model-residuals",
    "href": "lin_reg1.html#exploring-the-model-residuals",
    "title": "6  Linear Regression 1",
    "section": "Exploring the model: residuals",
    "text": "Exploring the model: residuals\n\n# what do our FITTED values look like?\nhead(fitted(fit_fp_lifetime_sum))\n\n       1        2        3        4        5        6 \n293.2915 293.2915 324.9926 293.2915 324.9926 293.2915 \n\n\n\n# what do our OBSERVED values look like?\nhead(df_crit_verb$fp)\n\n[1] 175 413 960 231 407 319\n\n\n\n# what is the difference between the FITTED and OBSERVED values?\nhead(df_crit_verb$fp) - head(fitted(fit_fp_lifetime_sum))\n\n         1          2          3          4          5          6 \n-118.29151  119.70849  635.00735  -62.29151   82.00735   25.70849 \n\n\n\n# what are our RESIDUALS?\nhead(residuals(fit_fp_lifetime_sum))\n\n         1          2          3          4          5          6 \n-118.29151  119.70849  635.00735  -62.29151   82.00735   25.70849"
  },
  {
    "objectID": "lin_reg1.html#exploring-the-model-1",
    "href": "lin_reg1.html#exploring-the-model-1",
    "title": "6  Linear Regression 1",
    "section": "Exploring the model",
    "text": "Exploring the model\n\nwhat were our coefficients?\n\n\ncoef(fit_fp_lifetime_sum)\n\n(Intercept)   lifetime1 \n  309.14208    31.70113 \n\n\n\nwhat is the mean of our predictor coded as -0.5?\n\n\ncoef(fit_fp_lifetime_sum)['(Intercept)'] + coef(fit_fp_lifetime_sum)['lifetime1'] * -0.5\n\n(Intercept) \n   293.2915 \n\n\n\nignore the (Intercept) label here, R just takes the first label when performing an operation on 2 vectors\nwhat is the mean of our predictor coded as +0.5?\n\n\ncoef(fit_fp_lifetime_sum)['(Intercept)'] + coef(fit_fp_lifetime_sum)['lifetime1'] * 0.5\n\n(Intercept) \n   324.9926"
  },
  {
    "objectID": "lin_reg1.html#important-terms",
    "href": "lin_reg1.html#important-terms",
    "title": "6  Linear Regression 1",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\nterm\ndescription/other terms\n\n\n\n\ndependent variable (DV)\noutcome, measure, y\n\n\nindependent variable (IV)\npredictor, fixed effect, y\n\n\nequation for a straight line\ny = intercept + slope*x\n\n\nsimple regression\npredicting outcome of a DV from a single IV\n\n\nslope\nchange in y (DV) associated with a 1-unit change in x (IV)\n\n\nintercept\nvalue of y (DV) when x (IV) = 0\n\n\nresiduals\ndifference between observed values and fitted/predicted values\n\n\nregression coefficients\nestimates of the unknown population parameters; intercept and slope\n\n\nleast squares\nthe method by which the line of best fit is determined; the line with the smallest sum of squared residuals"
  },
  {
    "objectID": "mult_reg.html",
    "href": "mult_reg.html",
    "title": "7  Multiple Regression",
    "section": "",
    "text": "Learning Objectives\nToday we will learn…\n# suppress scientific notation\noptions(scipen=999)\nChapters 6 and 7 in (winter_statistics_2019?)\n\\[\ny = b_0 + b_1x + b_2x + ... + e\n\\]\n\\[\nfp = b_0 + (b_1\\times lifetime) + (b_2\\times tense) + ... + e\n\\]\n\\[\ny = b_0 + b_1x_1 + b_2x_2 + b_3(x_1*x_2) + e\n\\]\n1.Run a model with main and interaction effects for tense and lifetime on total reading time at the verb region."
  },
  {
    "objectID": "mult_reg.html#packages",
    "href": "mult_reg.html#packages",
    "title": "7  Multiple Regression",
    "section": "Packages",
    "text": "Packages\nRun this in the Console:\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"strengejacke/sjPlot\")\n\nThen copy this into your script:\n\n# load libraries\npacman::p_load(\n  tidyverse,\n  here,\n  knitr,\n  kableExtra,\n  gt,\n  broom,\n  Rmisc,\n  patchwork,\n  sjPlot\n)"
  },
  {
    "objectID": "mult_reg.html#data",
    "href": "mult_reg.html#data",
    "title": "7  Multiple Regression",
    "section": "Data",
    "text": "Data\n\n# read in data\ndf_crit_verb &lt;- readr::read_csv(here::here(\"data/tidy_data_lifetime_pilot.csv\"), \n                               # for special characters\n                               locale = readr::locale(encoding = \"latin1\") \n                               ) |&gt; \n  mutate_if(is.character,as.factor) |&gt; # all character variables as factor\n  filter(type == \"critical\", # only critical trials\n         px != \"px3\",\n         region == \"verb\") |&gt;\n  droplevels()"
  },
  {
    "objectID": "mult_reg.html#set-contrasts",
    "href": "mult_reg.html#set-contrasts",
    "title": "7  Multiple Regression",
    "section": "8.1 Set contrasts",
    "text": "8.1 Set contrasts\nLet’s stick to sum contrast coding (+/-0.5).\n\n# order factor levels\ndf_crit_verb$lifetime &lt;- factor(df_crit_verb$lifetime, levels = c(\"living\",\"dead\"))\n# or using the tidyverse\ndf_crit_verb &lt;-\n  df_crit_verb %&gt;% \n  mutate(lifetime = fct_relevel(lifetime, \"living\", \"dead\"))\n\n\n# set contrasts\ncontrasts(df_crit_verb$lifetime) &lt;- c(-0.5,+0.5)\n\n\ncontrasts(df_crit_verb$lifetime)\n\n       [,1]\nliving -0.5\ndead    0.5"
  },
  {
    "objectID": "mult_reg.html#fit-model",
    "href": "mult_reg.html#fit-model",
    "title": "7  Multiple Regression",
    "section": "8.2 Fit model",
    "text": "8.2 Fit model\n\n# fit simple linear model\nfit_fp_lifetime &lt;- df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;%\n  lm(fp ~ lifetime, data = .)\n\n\n# check our contrasts\ncoef(fit_fp_lifetime)\n\n(Intercept)   lifetime1 \n  309.14208    31.70113"
  },
  {
    "objectID": "mult_reg.html#lifetime-effect",
    "href": "mult_reg.html#lifetime-effect",
    "title": "7  Multiple Regression",
    "section": "8.3 Lifetime Effect",
    "text": "8.3 Lifetime Effect\n\nrecall that we found a significant effect of lifetime\n\nthe dead conditions elicited longer first-pass reading times than the living conditions\n\nbut we also had two tenses: the Present Perfect (PP) and the Simple Future (SF)\n\nhow can we also check for an effect of tense?"
  },
  {
    "objectID": "mult_reg.html#another-linear-model",
    "href": "mult_reg.html#another-linear-model",
    "title": "7  Multiple Regression",
    "section": "8.4 Another linear model",
    "text": "8.4 Another linear model\n\nwe could run a second model with tense as the predictor instead of lifetime\n\n\ndf_crit_verb &lt;-\n  df_crit_verb %&gt;% \n  mutate(tense = fct_relevel(tense, \"PP\", \"SF\"))\n\n\ncontrasts(df_crit_verb$tense) &lt;- c(-0.5,+0.5)\n\n\ncontrasts(df_crit_verb$tense)\n\n   [,1]\nPP -0.5\nSF  0.5\n\n\n\n# fit simple linear model\nfit_fp_tense &lt;-\n  df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;%\n  lm(fp ~ tense, data = .)\n\n\n\nwhat does the summary tell us?\n\n\nsummary(fit_fp_tense)\n\n\nCall:\nlm(formula = fp ~ tense, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-232.75 -109.66  -28.57   61.84  768.43 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)  309.159      6.289  49.156 &lt;0.0000000000000002 ***\ntense1       -13.174     12.579  -1.047               0.295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 146.6 on 541 degrees of freedom\nMultiple R-squared:  0.002024,  Adjusted R-squared:  0.0001789 \nF-statistic: 1.097 on 1 and 541 DF,  p-value: 0.2954"
  },
  {
    "objectID": "mult_reg.html#adding-another-predictor",
    "href": "mult_reg.html#adding-another-predictor",
    "title": "7  Multiple Regression",
    "section": "9.1 Adding another predictor",
    "text": "9.1 Adding another predictor\n\nin our experimental design we were interested in the effect of lifetime on the processing of two different tenses: the Present Perfect and Simple Future\n\nin other words, we had two fixed factors: lifetime and tense\n\nmultiple regression is not the same as running separate simple linear models, rather each coefficient becomes a partial regression coefficient"
  },
  {
    "objectID": "mult_reg.html#fit-model-1",
    "href": "mult_reg.html#fit-model-1",
    "title": "7  Multiple Regression",
    "section": "9.2 Fit model",
    "text": "9.2 Fit model\n\nwe can use + to indicate we have another fixed effect, and that we want to look at the main effect of this predictor\n\n\n# multiple regression\nfit_fp &lt;-\n  df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;% \n  lm(fp ~ lifetime + tense, data = .)\n\n\n9.2.1 Model summary\n\nsummary(fit_fp)\n\n\nCall:\nlm(formula = fp ~ lifetime + tense, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-235.28 -107.36  -27.75   58.72  784.02 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)  309.130      6.258  49.394 &lt;0.0000000000000002 ***\nlifetime1     31.537     12.518   2.519               0.012 *  \ntense1       -12.768     12.518  -1.020               0.308    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 145.8 on 540 degrees of freedom\nMultiple R-squared:  0.01362,   Adjusted R-squared:  0.009964 \nF-statistic: 3.727 on 2 and 540 DF,  p-value: 0.02468"
  },
  {
    "objectID": "mult_reg.html#comparing-summaries",
    "href": "mult_reg.html#comparing-summaries",
    "title": "7  Multiple Regression",
    "section": "9.3 Comparing summaries",
    "text": "9.3 Comparing summaries\n\ntidy(fit_fp_lifetime) %&gt;% kable() %&gt;% kable_styling()\n\n\n\nTable 9.1: Coefficients for fit_fp_lifetime (fp ~ lifetime)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n309.14208\n6.258665\n49.39425\n0.0000000\n\n\nlifetime1\n31.70113\n12.517330\n2.53258\n0.0116043\n\n\n\n\n\n\n\n\n\ntidy(fit_fp_tense) %&gt;% kable() %&gt;% kable_styling()\n\n\n\nTable 9.2: Coefficients for fit_fp_tense (fp ~ tense)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n309.15914\n6.289283\n49.156500\n0.0000000\n\n\ntense1\n-13.17437\n12.578566\n-1.047366\n0.2953983\n\n\n\n\n\n\n\n\n\ntidy(fit_fp) %&gt;% kable() %&gt;% kable_styling()\n\n\n\nTable 9.3: Coefficients for fit_fp (fp ~ lifetime + tense)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n309.13047\n6.258442\n49.394159\n0.0000000\n\n\nlifetime1\n31.53658\n12.517903\n2.519318\n0.0120458\n\n\ntense1\n-12.76792\n12.517903\n-1.019973\n0.3081979"
  },
  {
    "objectID": "mult_reg.html#partial-regression-coefficients",
    "href": "mult_reg.html#partial-regression-coefficients",
    "title": "7  Multiple Regression",
    "section": "9.4 Partial regression coefficients",
    "text": "9.4 Partial regression coefficients\n\nin multiple regression, each predictor becomes a partial regression coefficient\n\nthe effect of one predictor while holding all other predictors constant\n\n\n\\[\n\\begin{align}\nfp &= 309.1 + (31.5\\times lifetime) + (-12.8\\times tense)\\\\\nfp_{dead-PP} &= 309.1 + (31.5\\times 0.5) + (-12.8\\times -0.5)\n\\end{align}\n\\]"
  },
  {
    "objectID": "mult_reg.html#exploring-the-model-fixed-effects",
    "href": "mult_reg.html#exploring-the-model-fixed-effects",
    "title": "7  Multiple Regression",
    "section": "Exploring the model: fixed effects",
    "text": "Exploring the model: fixed effects\n\nwhat were our coefficients?\n\n\ncoef(fit_fp)\n\n(Intercept)   lifetime1      tense1 \n  309.13047    31.53658   -12.76792 \n\n\n\nwhat is the mean of lifetime coded as -0.5 (living)?\n\n\ncoef(fit_fp)['(Intercept)'] + coef(fit_fp)['lifetime1'] * -0.5\n\n(Intercept) \n   293.3622 \n\n\n\nignore the (Intercept) label here, R just takes the first label when performing an operation on 2 vectors\nwhat is the mean of lifetime coded as +0.5 (dead)?\n\n\ncoef(fit_fp)['(Intercept)'] + coef(fit_fp)['lifetime1'] * 0.5\n\n(Intercept) \n   324.8988 \n\n\n\n9.4.1 Exercise\n\ndo the same for tense:\n\nfind the fitted value for PP and for SF"
  },
  {
    "objectID": "mult_reg.html#exploring-the-model-predicting-fp",
    "href": "mult_reg.html#exploring-the-model-predicting-fp",
    "title": "7  Multiple Regression",
    "section": "9.5 Exploring the model: predicting fp",
    "text": "9.5 Exploring the model: predicting fp\n\n\n\n\n\n\nTable 9.4: Coefficient estimates\n\n\nterm\nestimate\n*0.5\n\n\n\n\n(Intercept)\n309.1\n154.6\n\n\nlifetime1\n31.5\n15.8\n\n\ntense1\n-12.8\n-6.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 9.5: Fitted values per condition\n\n\nlifetime\ntense\n.fitted\nfp\nmean_diff\n\n\n\n\nliving\nPP\n299.7\n294.3\n-5.5\n\n\nliving\nSF\n287.0\n292.4\n5.4\n\n\ndead\nPP\n331.3\n336.6\n5.3\n\n\ndead\nSF\n318.5\n313.0\n-5.5\n\n\n\n\n\n\n\n\n\n\n\n9.5.1 Calculating fitted values by hand\n\\[\nfp = b_0 + (b_1\\times lifetime) + (b_2\\times tense) + e\n\\]\n\n# living-PP\ncoef(fit_fp)['(Intercept)'] + \n  coef(fit_fp)['lifetime1'] * -0.5 + coef(fit_fp)['tense1'] * -0.5 \n\n(Intercept) \n   299.7461 \n\n\n\n# living-SF\ncoef(fit_fp)['(Intercept)'] + \n  coef(fit_fp)['lifetime1'] * -0.5 + coef(fit_fp)['tense1'] * 0.5 \n\n(Intercept) \n   286.9782 \n\n\n\n# dead-PP\ncoef(fit_fp)['(Intercept)'] + \n  coef(fit_fp)['lifetime1'] * 0.5 + coef(fit_fp)['tense1'] * -0.5 \n\n(Intercept) \n   331.2827 \n\n\n\n# dead-SF\ncoef(fit_fp)['(Intercept)'] + \n  coef(fit_fp)['lifetime1'] * 0.5 + coef(fit_fp)['tense1'] * 0.5 \n\n(Intercept) \n   318.5148"
  },
  {
    "objectID": "mult_reg.html#exploring-the-model-residuals",
    "href": "mult_reg.html#exploring-the-model-residuals",
    "title": "7  Multiple Regression",
    "section": "Exploring the model: residuals",
    "text": "Exploring the model: residuals\n\nrecall that residuals = the difference between our fitted (model) values and our observed (data) values\n\n\n# what do our FITTED values look like?\nhead(fitted(fit_fp))\n\n       1        2        3        4        5        6 \n299.7461 299.7461 331.2827 299.7461 318.5148 286.9782 \n\n\n\n# what do our OBSERVED values look like?\nhead(df_crit_verb$fp)\n\n[1] 175 413 960 231 407 319\n\n\n\n# what is the difference between the FITTED and OBSERVED values?\nhead(df_crit_verb$fp) - head(fitted(fit_fp))\n\n         1          2          3          4          5          6 \n-124.74615  113.25385  628.71727  -68.74615   88.48520   32.02178 \n\n\n\n# what are our RESIDUALS?\nhead(residuals(fit_fp))\n\n         1          2          3          4          5          6 \n-124.74615  113.25385  628.71727  -68.74615   88.48520   32.02178"
  },
  {
    "objectID": "mult_reg.html#plotting-our-effects",
    "href": "mult_reg.html#plotting-our-effects",
    "title": "7  Multiple Regression",
    "section": "9.6 Plotting our effects",
    "text": "9.6 Plotting our effects\n\nbased on these plots, it seems like the effects of lifetime and tense differed\n\nthe slant in figure A (effect of lifetime) looks steeper for the PP than the SF\n\nthis could reflect an interaction effect\n\n\n\n\n\n\nFigure 9.1: Plotting our two predictors\n\n\n\n\n\n9.6.1 Plotting coefficients with sjPlot\n\nplot_model(fit_fp) +\n  geom_hline(yintercept=0) +\n  theme_bw()"
  },
  {
    "objectID": "mult_reg.html#fitting-an-interaction-term-to-our-model",
    "href": "mult_reg.html#fitting-an-interaction-term-to-our-model",
    "title": "7  Multiple Regression",
    "section": "10.1 Fitting an interaction term to our model",
    "text": "10.1 Fitting an interaction term to our model\n\nto add an interaction, we can use a colon to separate two variables\n\nlifetime:tense\n\nhowever, it’s common to use an asterisk instead, which means “fit main effects of these variables and their interaction*\n\nlifetime:tense\n\n\n\n# multiple regression\nfit_fp_inter &lt;-\n  df_crit_verb %&gt;%\n  filter(fp &gt; 0) %&gt;% \n  lm(fp ~ lifetime*tense, data = .)\n\n\nsummary(fit_fp_inter)\n\n\nCall:\nlm(formula = fp ~ lifetime * tense, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-240.62 -108.69  -27.62   56.20  778.65 \n\nCoefficients:\n                 Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)        309.06       6.26  49.367 &lt;0.0000000000000002 ***\nlifetime1           31.52      12.52   2.517              0.0121 *  \ntense1             -12.75      12.52  -1.018              0.3090    \nlifetime1:tense1   -21.69      25.04  -0.866              0.3868    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 145.9 on 539 degrees of freedom\nMultiple R-squared:  0.01499,   Adjusted R-squared:  0.009506 \nF-statistic: 2.734 on 3 and 539 DF,  p-value: 0.04306"
  },
  {
    "objectID": "mult_reg.html#plotting-an-interaction",
    "href": "mult_reg.html#plotting-an-interaction",
    "title": "7  Multiple Regression",
    "section": "10.2 Plotting an interaction",
    "text": "10.2 Plotting an interaction\n\n\n\n\n\nFigure 10.1: Plotting our two predictors\n\n\n\n\n\n10.2.1 Plotting an interaction with sjPlot\n\nfig_sjplot_coef &lt;- plot_model(fit_fp_inter) +\n  geom_hline(yintercept=0) +\n  theme_bw()\n\nfig_sjplot_int &lt;- plot_model(fit_fp_inter, type = \"int\") +\n  geom_hline(yintercept=0) +\n  geom_line(group=1) +\n  theme_bw()\n\n\nfig_sjplot_coef + fig_sjplot_int + plot_annotation(tag_levels = \"A\")\n\n\n\n\nFigure 10.2: Plotting model coefficients (A) and interactions (B) with the sjPlot package"
  }
]